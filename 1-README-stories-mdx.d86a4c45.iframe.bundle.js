/*! For license information please see 1-README-stories-mdx.d86a4c45.iframe.bundle.js.LICENSE.txt */
(self.webpackChunkopenai_ext=self.webpackChunkopenai_ext||[]).push([[836],{"./node_modules/@mdx-js/react/lib/index.js":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{"use strict";__webpack_require__.d(__webpack_exports__,{Ck:()=>withMDXComponents,Eh:()=>MDXContext,Iu:()=>MDXProvider,MN:()=>useMDXComponents});var react__WEBPACK_IMPORTED_MODULE_0__=__webpack_require__("./node_modules/react/index.js");const MDXContext=react__WEBPACK_IMPORTED_MODULE_0__.createContext({});function withMDXComponents(Component){return function boundMDXComponent(props){const allComponents=useMDXComponents(props.components);return react__WEBPACK_IMPORTED_MODULE_0__.createElement(Component,{...props,allComponents})}}function useMDXComponents(components){const contextComponents=react__WEBPACK_IMPORTED_MODULE_0__.useContext(MDXContext);return react__WEBPACK_IMPORTED_MODULE_0__.useMemo((()=>"function"==typeof components?components(contextComponents):{...contextComponents,...components}),[contextComponents,components])}const emptyObject={};function MDXProvider({components,children,disableParentContext}){let allComponents;return allComponents=disableParentContext?"function"==typeof components?components({}):components||emptyObject:useMDXComponents(components),react__WEBPACK_IMPORTED_MODULE_0__.createElement(MDXContext.Provider,{value:allComponents},children)}},"./node_modules/@storybook/addon-docs/dist/index.mjs":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{"use strict";__webpack_require__.d(__webpack_exports__,{Qb:()=>_storybook_blocks__WEBPACK_IMPORTED_MODULE_1__.Qb});__webpack_require__("./node_modules/@storybook/addon-docs/dist/chunk-HLWAVYOI.mjs");var _storybook_blocks__WEBPACK_IMPORTED_MODULE_1__=__webpack_require__("./node_modules/@storybook/blocks/dist/index.mjs")},"./src/stories/core/1.README.stories.mdx":(__unused_webpack_module,__webpack_exports__,__webpack_require__)=>{"use strict";__webpack_require__.r(__webpack_exports__),__webpack_require__.d(__webpack_exports__,{__namedExportsOrder:()=>__namedExportsOrder,__page:()=>__page,default:()=>_1_README_stories});__webpack_require__("./node_modules/react/index.js");var lib=__webpack_require__("./node_modules/@mdx-js/react/lib/index.js"),dist=__webpack_require__("./node_modules/@storybook/addon-docs/dist/index.mjs"),blocks_dist=__webpack_require__("./node_modules/@storybook/blocks/dist/index.mjs");const READMEraw_namespaceObject='<h2 align="center">\n  ğŸ¤– openai-ext\n</h2>\n<h3 align="center">\n  Extension to OpenAI\'s API to support streaming chat completions.\n</h3>\n<p align="center">\n  <a href="https://badge.fury.io/js/openai-ext" target="_blank" rel="noopener noreferrer"><img src="https://badge.fury.io/js/openai-ext.svg" alt="npm Version" /></a>&nbsp;\n  <a href="https://github.com/justinmahar/openai-ext/" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/badge/GitHub-Source-success" alt="View project on GitHub" /></a>&nbsp;\n  <a href="https://github.com/justinmahar/openai-ext/actions?query=workflow%3ADeploy" target="_blank" rel="noopener noreferrer"><img src="https://github.com/justinmahar/openai-ext/workflows/Deploy/badge.svg" alt="Deploy Status" /></a>\n</p>\n\x3c!-- [lock:donate-badges] ğŸš«--------------------------------------- --\x3e\n<p align="center">\n  <a href="https://paypal.me/thejustinmahar/5"><img src="https://img.shields.io/static/v1?label=Buy%20me%20a%20coffee&message=%E2%9D%A4&logo=KoFi&color=%23fe8e86" alt="Buy me a coffee" /></a>&nbsp;<a href="https://github.com/sponsors/justinmahar" target="_blank" rel="noopener noreferrer"><img src="https://img.shields.io/static/v1?label=Sponsor&message=%E2%9D%A4&logo=GitHub&color=%23fe8e86" alt="Sponsor"/></a>\n</p>\n\x3c!-- [/lock:donate-badges] ---------------------------------------ğŸš« --\x3e\n\n<h3><a href="https://justinmahar.github.io/openai-ext/?path=/story/demo--client">ğŸ‘ï¸ Live Demo</a></h3>\n\n<a href="https://justinmahar.github.io/openai-ext/?path=/story/demo--client">\n<img src="https://raw.githubusercontent.com/justinmahar/openai-ext/master/public/demo.gif" alt="Live Demo" /></a>\n\n## Documentation\n\nRead the **[official documentation](https://justinmahar.github.io/openai-ext/)**.\n\n<a href="https://justinmahar.github.io/openai-ext/?path=/story/demo--client">View the live demo.</a>\n\n## Overview\n\nThis project extends OpenAI\'s API to support streaming chat completions on both the server (Node.js) and client (browser).\n\n> Note: This is an unofficial working solution until OpenAI adds streaming support. This issue is being tracked here: [How to use stream: true? #18](https://github.com/openai/openai-node/issues/18).\n\n### Features include:\n\n- **ğŸ’» Support for streaming chat completions**\n  - Easy to use API extension for chat completion streaming support.\n- **âš™ï¸ Easy to configure**\n  - Dead simple configuration for API and stream handlers.\n- **ğŸ“œ Content draft parsing**\n  - Content is parsed for you and provided in an easy to digest format as it streams.\n- **ğŸŒ Works in both server (Node.js) and client (browser) environments**\n  - Stream completions in either environment: Node.js or in the browser!\n- **ğŸ›‘ Support for stopping completions**\n  - Stop completions before they finish, just like ChatGPT allows.\n\n\x3c!-- [lock:donate] ğŸš«--------------------------------------- --\x3e\n\n## Donate \n\nIf this project helped save you time, please consider buying me a coffee, which powers my development (and life). Your support is much appreciated!\n\n<a href="https://github.com/sponsors/justinmahar"><img src="https://justinmahar.github.io/react-kindling/support/sponsor.png" alt="Sponsor via GitHub" height="35" /></a>&nbsp; <a href="https://paypal.me/thejustinmahar/5"><img src="https://justinmahar.github.io/react-kindling/support/coffee-1.png" alt="Buy me a coffee" height="35" /></a>&nbsp; <a href="https://paypal.me/thejustinmahar/15"><img src="https://justinmahar.github.io/react-kindling/support/coffee-3.png" alt="Buy me 3 coffees" height="35" /></a>&nbsp; <a href="https://paypal.me/thejustinmahar/25"><img src="https://justinmahar.github.io/react-kindling/support/coffee-5.png" alt="Buy me 5 coffees" height="35" /></a>\n\n\x3c!-- [/lock:donate] ---------------------------------------ğŸš« --\x3e\n\n## Table of Contents \n\n- [Documentation](#documentation)\n- [Overview](#overview)\n  - [Features include:](#features-include)\n- [Donate](#donate)\n- [Table of Contents](#table-of-contents)\n- [Installation](#installation)\n- [Quick Start](#quick-start)\n  - [Browser / Client](#browser--client)\n  - [Node.js / Server](#nodejs--server)\n- [Content Parsing Utility](#content-parsing-utility)\n- [TypeScript](#typescript)\n- [Icon Attribution](#icon-attribution)\n- [Contributing](#contributing)\n- [â­ Found It Helpful? Star It!](#-found-it-helpful-star-it)\n- [License](#license)\n\n## Installation\n\n```\nnpm i openai-ext\n```\n\n## Quick Start\n\n### Browser / Client\n\n<a href="https://justinmahar.github.io/openai-ext/?path=/story/demo--client">View the live demo.</a>\n\nUse the following solution in a browser environment:\n\n```js\nimport { OpenAIExt } from "openai-ext";\n\n// Configure the stream (use type ClientStreamChatCompletionConfig for TypeScript users)\nconst streamConfig = {\n  apiKey: `123abcXYZasdf`, // Your API key\n  handler: {\n    // Content contains the string draft, which may be partial. When isFinal is true, the completion is done.\n    onContent(content, isFinal, xhr) {\n      console.log(content, "isFinal?", isFinal);\n    },\n    onDone(xhr) {\n      console.log("Done!");\n    },\n    onError(error, status, xhr) {\n      console.error(error);\n    },\n  },\n};\n\n// Make the call and store a reference to the XMLHttpRequest\nconst xhr = OpenAIExt.streamClientChatCompletion(\n  {\n    model: "gpt-3.5-turbo",\n    messages: [\n      { role: "system", content: "You are a helpful assistant." },\n      { role: "user", content: "Tell me a funny joke." },\n    ],\n  },\n  streamConfig\n);\n```\n\n```js\n// If you\'d like to stop the completion, call xhr.abort(). The onDone() handler will be called.\nxhr.abort();\n```\n\n### Node.js / Server\n\nUse the following solution in a Node.js or server environment:\n\n```js\nimport { Configuration, OpenAIApi } from \'openai\';\nimport { OpenAIExt } from "openai-ext";\n\nconst apiKey = `123abcXYZasdf`; // Your API key\nconst configuration = new Configuration({ apiKey });\nconst openai = new OpenAIApi(configuration);\n\n// Configure the stream (use type ServerStreamChatCompletionConfig for TypeScript users)\nconst streamConfig = {\n  openai: openai,\n  handler: {\n    // Content contains the string draft, which may be partial. When isFinal is true, the completion is done.\n    onContent(content, isFinal, stream) {\n      console.log(content, "isFinal?", isFinal);\n    },\n    onDone(stream) {\n      console.log(\'Done!\');\n    },\n    onError(error, stream) {\n      console.error(error);\n    },\n  },\n};\n\nconst axiosConfig = {\n  // ...\n};\n\n// Make the call to stream the completion\nOpenAIExt.streamServerChatCompletion(\n  {\n    model: \'gpt-3.5-turbo\',\n    messages: [\n      { role: \'system\', content: \'You are a helpful assistant.\' },\n      { role: \'user\', content: \'Tell me a funny joke.\' },\n    ],\n  },\n  streamConfig,\n  axiosConfig\n);\n```\n\nIf you\'d like to stop the completion, call `stream.destroy()`. The `onDone()` handler will be called.\n\n```js\nconst response = await OpenAIExt.streamServerChatCompletion(...);\nconst stream = response.data;\nstream.destroy();\n```\n\nYou can also stop completion using an [Axios cancellation](https://axios-http.com/docs/cancellation) in the Axios config (pending [#134](https://github.com/openai/openai-node/issues/134)).\n\n## Content Parsing Utility\n\nUnder the hood, the function `OpenAIExt.parseContentDraft(dataString)` is used to extract completion content from a data string when streaming data in this library.\n\nFeel free to use this if you\'d like to handle streaming in a different way than this library provides.\n\nThe data string contains lines of JSON completion data starting with `data: ` that are separated by two newlines. \nThe completion is terminated by the line `data: [DONE]` when the completion content can be considered final and done.\n\nWhen passed a data string, the function returns completion content in the following shape:\n\n```ts\n{\n  content: string; // Content string. May be partial.\n  isFinal: boolean; // When true, the content string is complete and the completion is done.\n}\n```\n\nIf you\'re using this library for streaming completions, parsing is handled for you automatically and the result will be provided via the `onContent` handler callback documented above.\n\n\x3c!-- [lock:typescript] ğŸš«--------------------------------------- --\x3e\n\n## TypeScript\n\nType definitions have been included for [TypeScript](https://www.typescriptlang.org/) support.\n\n\x3c!-- [/lock:typescript] ---------------------------------------ğŸš« --\x3e\n\n\x3c!-- [lock:icon] ğŸš«--------------------------------------- --\x3e\n\n## Icon Attribution\n\nFavicon by [Twemoji](https://github.com/twitter/twemoji).\n\n\x3c!-- [/lock:icon] ---------------------------------------ğŸš« --\x3e\n\n\x3c!-- [lock:contributing] ğŸš«--------------------------------------- --\x3e\n\n## Contributing\n\nOpen source software is awesome and so are you. ğŸ˜\n\nFeel free to submit a pull request for bugs or additions, and make sure to update tests as appropriate. If you find a mistake in the docs, send a PR! Even the smallest changes help.\n\nFor major changes, open an issue first to discuss what you\'d like to change.\n\n\x3c!-- [/lock:contributing] --------------------------------------ğŸš« --\x3e\n\n## â­ Found It Helpful? [Star It!](https://github.com/justinmahar/openai-ext/stargazers)\n\nIf you found this project helpful, let the community know by giving it a [star](https://github.com/justinmahar/openai-ext/stargazers): [ğŸ‘‰â­](https://github.com/justinmahar/openai-ext/stargazers)\n\n\x3c!-- [lock:support] ğŸš«--------------------------------------- --\x3e\nWant to support the project? Feel free to grab me a coffee, which is my main source of fuel for development:\n\n<a href="https://paypal.me/thejustinmahar/5"><img src="https://justinmahar.github.io/react-kindling/support/coffee-1.png" alt="Buy me a coffee" height="35" /></a>&nbsp; <a href="https://paypal.me/thejustinmahar/15"><img src="https://justinmahar.github.io/react-kindling/support/coffee-3.png" alt="Buy me 3 coffees" height="35" /></a>&nbsp; <a href="https://paypal.me/thejustinmahar/25"><img src="https://justinmahar.github.io/react-kindling/support/coffee-5.png" alt="Buy me 5 coffees" height="35" /></a>\n\n\x3c!-- [/lock:support] ---------------------------------------ğŸš« --\x3e\n\n## License\n\nSee [LICENSE.md](https://justinmahar.github.io/openai-ext/?path=/docs/license--docs).';var jsx_runtime=__webpack_require__("./node_modules/react/jsx-runtime.js");function _createMdxContent(props){return(0,jsx_runtime.jsxs)(jsx_runtime.Fragment,{children:[(0,jsx_runtime.jsx)(dist.Qb,{title:"Home"}),"\n",(0,jsx_runtime.jsx)(blocks_dist.Ih,{children:READMEraw_namespaceObject})]})}const __page=()=>{throw new Error("Docs-only story")};__page.parameters={docsOnly:!0};const componentMeta={title:"Home",tags:["stories-mdx"],includeStories:["__page"]};componentMeta.parameters=componentMeta.parameters||{},componentMeta.parameters.docs={...componentMeta.parameters.docs||{},page:function MDXContent(props={}){const{wrapper:MDXLayout}=Object.assign({},(0,lib.MN)(),props.components);return MDXLayout?(0,jsx_runtime.jsx)(MDXLayout,{...props,children:(0,jsx_runtime.jsx)(_createMdxContent,{...props})}):_createMdxContent()}};const _1_README_stories=componentMeta,__namedExportsOrder=["__page"]},"./node_modules/memoizerific sync recursive":module=>{function webpackEmptyContext(req){var e=new Error("Cannot find module '"+req+"'");throw e.code="MODULE_NOT_FOUND",e}webpackEmptyContext.keys=()=>[],webpackEmptyContext.resolve=webpackEmptyContext,webpackEmptyContext.id="./node_modules/memoizerific sync recursive",module.exports=webpackEmptyContext},"./node_modules/react/cjs/react-jsx-runtime.production.min.js":(__unused_webpack_module,exports,__webpack_require__)=>{"use strict";var f=__webpack_require__("./node_modules/react/index.js"),k=Symbol.for("react.element"),l=Symbol.for("react.fragment"),m=Object.prototype.hasOwnProperty,n=f.__SECRET_INTERNALS_DO_NOT_USE_OR_YOU_WILL_BE_FIRED.ReactCurrentOwner,p={key:!0,ref:!0,__self:!0,__source:!0};function q(c,a,g){var b,d={},e=null,h=null;for(b in void 0!==g&&(e=""+g),void 0!==a.key&&(e=""+a.key),void 0!==a.ref&&(h=a.ref),a)m.call(a,b)&&!p.hasOwnProperty(b)&&(d[b]=a[b]);if(c&&c.defaultProps)for(b in a=c.defaultProps)void 0===d[b]&&(d[b]=a[b]);return{$$typeof:k,type:c,key:e,ref:h,props:d,_owner:n.current}}exports.Fragment=l,exports.jsx=q,exports.jsxs=q},"./node_modules/react/jsx-runtime.js":(module,__unused_webpack_exports,__webpack_require__)=>{"use strict";module.exports=__webpack_require__("./node_modules/react/cjs/react-jsx-runtime.production.min.js")}}]);